{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DpQmIE2afr2z",
    "outputId": "ca253041-5875-4c3a-fc2f-0b6fe160f5c9"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U41bnW2ClpzI"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oEI4pzlXllKP"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/drive/My Drive/cosc522/finalproject/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s78tRVpzsej-",
    "outputId": "dd2e53e1-c896-4588-9e37-d6b704437e2a"
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Bankrupt?'])\n",
    "y = df['Bankrupt?']\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9UZFY-kykaq"
   },
   "source": [
    "Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CksUiIlyjue",
    "outputId": "e2a2cc1c-012b-4544-eb4f-064057e2eb9a"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(\"Original class distribution in training set:\")\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vy0mwfxbq_ZE"
   },
   "source": [
    "# Pre-process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LtiVKhmNlunG"
   },
   "source": [
    "## Correlation analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "s9sMajXmluNG",
    "outputId": "e6ec3325-c87c-42c6-d82f-6521e67a5ebf"
   },
   "outputs": [],
   "source": [
    "\"\"\" Analyze the Correlation between features \"\"\"\n",
    "\n",
    "X_corr = X.corr()\n",
    "\n",
    "# filter features that has correlation > 0.5\n",
    "plt.figure(figsize=(14, 12))\n",
    "filtered_X_corr = X_corr[(X_corr >= 0.8) | (X_corr <= -0.8)]\n",
    "sns.heatmap(X_corr, annot=True,\n",
    "            cmap='coolwarm',\n",
    "            vmin = -1,\n",
    "            vmax = 1,\n",
    "            linewidths= 0.5,\n",
    "            annot_kws={\"size\":1},\n",
    "            cbar = True,\n",
    "            xticklabels=2,\n",
    "            yticklabels=2)\n",
    "plt.show()\n",
    "plt.savefig('/content/drive/My Drive/cosc522/finalproject/corr.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_2JLmAAxqfKA",
    "outputId": "f45172a1-8e18-4c44-a93f-0e8db4135b6b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "threshold = 0.8\n",
    "\n",
    "\n",
    "high_corr_pairs = X_corr.where((X_corr > threshold) & (X_corr != 1)).stack().reset_index()\n",
    "high_corr_pairs.columns = ['Feature_1', 'Feature_2', 'Correlation']\n",
    "\n",
    "\n",
    "print(high_corr_pairs)\n",
    "print(high_corr_pairs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-BRYxZbvquG2"
   },
   "source": [
    "## Data Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbyqM_5rrNsL"
   },
   "source": [
    "### StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aUQLrg5EqttA"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# initial StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4moaG-torToZ"
   },
   "source": [
    "### MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wGs0Ao4UrVlL"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# initial MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GIbAbORQrYaF"
   },
   "source": [
    "### RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bZHe9YbArc2X"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# initial RobustScaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "X_train_robust = scaler.fit_transform(X_train)\n",
    "X_test_robust = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mk_raz3FrsCJ"
   },
   "source": [
    "## Feature processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2zCN8nttOZW"
   },
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FZd02Rr1ry8l",
    "outputId": "682cbd9d-5517-491c-ef6a-7c92d7be7e7b"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "high_corr_features = list(set(high_corr_pairs['Feature_1']).union(set(high_corr_pairs['Feature_2'])))\n",
    "print(len(high_corr_features))\n",
    "# combine 32 feature to 1\n",
    "# X_for_pca = X_train.copy()\n",
    "\n",
    "PCA_list = [1, 2, 4, 8, 16]\n",
    "X_pca_list = []\n",
    "XT_pca_list = []\n",
    "\n",
    "\n",
    "for n_comp in PCA_list:\n",
    "    X_for_pca = X_train.copy()\n",
    "    XT_for_pca = X_test.copy()\n",
    "\n",
    "\n",
    "    pca = PCA(n_components=n_comp)\n",
    "\n",
    "    X_train_pca = pca.fit_transform(X_for_pca[high_corr_features])\n",
    "\n",
    "    X_test_pca = pca.transform(XT_for_pca[high_corr_features])\n",
    "\n",
    "    X_train_pca_df = pd.DataFrame(X_train_pca, columns=[f'PCA_{i+1}' for i in range(X_train_pca.shape[1])], index=X_for_pca.index)\n",
    "    X_test_pca_df = pd.DataFrame(X_test_pca, columns=[f'PCA_{i+1}' for i in range(X_test_pca.shape[1])], index=XT_for_pca.index)\n",
    "\n",
    "    X_train_final = X_for_pca.drop(columns=high_corr_features).join(X_train_pca_df)\n",
    "    X_test_final = XT_for_pca.drop(columns=high_corr_features).join(X_test_pca_df)\n",
    "\n",
    "    print(f\"PCA with {n_comp} components:\")\n",
    "    print(\"Training set shape after PCA:\", X_train_final.shape)\n",
    "    print(\"Test set shape after PCA:\", X_test_final.shape)\n",
    "\n",
    "    X_pca_list.append(X_train_final)\n",
    "    XT_pca_list.append(X_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7JS3lFo0GPC"
   },
   "source": [
    "### 95% pca on high corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wUKx_rDz0FhA",
    "outputId": "335e04a2-0e12-4a69-ee92-e2980eee2642"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "high_corr_features = list(set(high_corr_pairs['Feature_1']).union(set(high_corr_pairs['Feature_2'])))\n",
    "print(len(high_corr_features))\n",
    "# combine 32 feature to 1\n",
    "# X_for_pca = X_train.copy()\n",
    "\n",
    "X_for_pca = X_train.copy()\n",
    "XT_for_pca = X_test.copy()\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_for_pca[high_corr_features])\n",
    "\n",
    "X_test_pca = pca.transform(XT_for_pca[high_corr_features])\n",
    "\n",
    "X_train_pca_df = pd.DataFrame(X_train_pca, columns=[f'PCA_{i+1}' for i in range(X_train_pca.shape[1])], index=X_for_pca.index)\n",
    "X_test_pca_df = pd.DataFrame(X_test_pca, columns=[f'PCA_{i+1}' for i in range(X_test_pca.shape[1])], index=XT_for_pca.index)\n",
    "\n",
    "X_pca_list_95 = X_for_pca.drop(columns=high_corr_features).join(X_train_pca_df)\n",
    "XT_pca_list_95 = XT_for_pca.drop(columns=high_corr_features).join(X_test_pca_df)\n",
    "\n",
    "print(f\"PCA with {n_comp} components:\")\n",
    "print(\"Training set shape after PCA:\", X_pca_list_95.shape)\n",
    "print(\"Test set shape after PCA:\", XT_pca_list_95.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "lG8rtrp2100C",
    "outputId": "1a744cf0-88ef-46d5-cee2-63dda2a04769"
   },
   "outputs": [],
   "source": [
    "cumulative_variance = pca.explained_variance_ratio_.cumsum()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', linestyle='--')\n",
    "plt.axhline(y=0.95, color='r', linestyle='--', label=\"95% Variance\")\n",
    "plt.axvline(x=pca.n_components_, color='r', linestyle='--', label=f\"{pca.n_components_} Components\")\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('PCA Explained Variance')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yQntpVRH0nKV",
    "outputId": "509deb29-98da-4c73-b6ab-16a2e52e7822"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "class_counts = y_train.value_counts()\n",
    "scale_pos_weight = class_counts[0] / class_counts[1]\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_pca_list_95)\n",
    "X_test_pca = scaler.transform(XT_pca_list_95)\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Resampled class distribution in training set:\")\n",
    "print(y_train_resampled.value_counts())\n",
    "\n",
    "model = XGBClassifier(random_state=42)\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test_pca)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zX7zLEkd36XY",
    "outputId": "f64bcad0-d09c-4c8d-c38e-0ae67ae84a06"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "class_counts = y_train.value_counts()\n",
    "scale_pos_weight = class_counts[0] / class_counts[1]\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_pca_list_95)\n",
    "X_test_pca = scaler.transform(XT_pca_list_95)\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Resampled class distribution in training set:\")\n",
    "print(y_train_resampled.value_counts())\n",
    "\n",
    "model = XGBClassifier(random_state=42)\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test_pca)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bw7vAIMJ4D8r",
    "outputId": "4d0abee5-e94b-4d58-edd3-e39bf3deae8b"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "class_counts = y_train.value_counts()\n",
    "scale_pos_weight = class_counts[0] / class_counts[1]\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_pca_list_95)\n",
    "X_test_pca = scaler.transform(XT_pca_list_95)\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Resampled class distribution in training set:\")\n",
    "print(y_train_resampled.value_counts())\n",
    "\n",
    "model = XGBClassifier(random_state=42)\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test_pca)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M72_86q8c3VM"
   },
   "source": [
    "### StandarScaler PCA in full feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BjCWAIbzc6M8",
    "outputId": "ddc91fb1-b4f4-4753-ec40-cf1f4a24c9a3"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=None)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_variance = explained_variance_ratio.cumsum()\n",
    "\n",
    "print(\"Explained Variance Ratio for each component:\")\n",
    "print(explained_variance_ratio)\n",
    "\n",
    "print(\"Cumulative Explained Variance:\")\n",
    "print(cumulative_variance)\n",
    "\n",
    "print(f\"Number of components to retain 95% variance: {n_components}\")\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca_full = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca_full = pca.transform(X_test_scaled)\n",
    "\n",
    "print(f\"Shape after PCA: X_train {X_train_pca.shape}, X_test {X_test_pca.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2PMl2ODnd5cN",
    "outputId": "5471fa8a-3e0c-4eca-812b-4e221a7ddb07"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "class_counts = y_train.value_counts()\n",
    "scale_pos_weight = class_counts[0] / class_counts[1]\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_pca_full, y_train)\n",
    "\n",
    "print(\"Resampled class distribution in training set:\")\n",
    "print(y_train_resampled.value_counts())\n",
    "\n",
    "model = XGBClassifier(random_state=42)\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test_pca_full)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lietgrl2q9NU"
   },
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SVyDjy6JrHTs"
   },
   "source": [
    "### MinMaxScaler PCA in full features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OWB42-14rM9y",
    "outputId": "98664347-e9d2-4f04-80d3-b893ac2581b0"
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "pca = PCA(n_components=None)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_variance = explained_variance_ratio.cumsum()\n",
    "\n",
    "print(\"Explained Variance Ratio for each component:\")\n",
    "print(explained_variance_ratio)\n",
    "\n",
    "print(\"Cumulative Explained Variance:\")\n",
    "print(cumulative_variance)\n",
    "\n",
    "n_components = sum(cumulative_variance < 0.95) + 1\n",
    "print(f\"Number of components to retain 95% variance: {n_components}\")\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca_full = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca_full = pca.transform(X_test_scaled)\n",
    "\n",
    "print(f\"Shape after PCA: X_train {X_train_pca.shape}, X_test {X_test_pca.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lcGdi4cIrRW2",
    "outputId": "b8bda0d7-4a6e-40d5-a103-7844f3eec771"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "class_counts = y_train.value_counts()\n",
    "scale_pos_weight = class_counts[0] / class_counts[1]\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_pca_full, y_train)\n",
    "\n",
    "print(\"Resampled class distribution in training set:\")\n",
    "print(y_train_resampled.value_counts())\n",
    "\n",
    "model = XGBClassifier(random_state=42)\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test_pca_full)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45M-36vSrpS1"
   },
   "source": [
    "### RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dmq4R9versyi",
    "outputId": "b2b0c0ea-e6f2-4eae-c7bc-d62040ec7699"
   },
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=None)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_variance = explained_variance_ratio.cumsum()\n",
    "\n",
    "print(\"Explained Variance Ratio for each component:\")\n",
    "print(explained_variance_ratio)\n",
    "\n",
    "print(\"Cumulative Explained Variance:\")\n",
    "print(cumulative_variance)\n",
    "\n",
    "n_components = sum(cumulative_variance < 0.95) + 1\n",
    "print(f\"Number of components to retain 95% variance: {n_components}\")\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca_full = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca_full = pca.transform(X_test_scaled)\n",
    "\n",
    "print(f\"Shape after PCA: X_train {X_train_pca.shape}, X_test {X_test_pca.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hE8g72T4rxtc",
    "outputId": "e394a064-54e3-4aed-cc85-eadf9d277527"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "class_counts = y_train.value_counts()\n",
    "scale_pos_weight = class_counts[0] / class_counts[1]\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_pca_full, y_train)\n",
    "\n",
    "print(\"Resampled class distribution in training set:\")\n",
    "print(y_train_resampled.value_counts())\n",
    "\n",
    "model = XGBClassifier(random_state=42)\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test_pca_full)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iFpH0hKRy4JS"
   },
   "source": [
    "# Classifiy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrBE6eNebd8d"
   },
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFgtiYHr_zWa"
   },
   "source": [
    "### only XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PRZXX4Z__1q0",
    "outputId": "134d8e6d-0ac1-4e37-daf7-d6aa9ec0959e"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6r92EeCdbOf2"
   },
   "source": [
    "### SMOTE+XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "opCWrvj0CW7x",
    "outputId": "b704086d-fbea-4604-e7b1-21b9777febc6"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "xgb_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CvsR9mvZCx8f",
    "outputId": "7794a1e3-fd95-4942-c300-ad0a03b0f600"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
    "                           param_grid=param_grid, scoring='f1', cv=3, verbose=2, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "print(\"Classification Report with Best Parameters:\")\n",
    "print(classification_report(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TulESSJ99B3T"
   },
   "source": [
    "### StandardScaler+SMOTE+XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mrQmWQOm9Lqg",
    "outputId": "1046a87d-2116-4b68-e342-2a2628c844c6"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "xgb_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test_scaled)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WIcnBKZ69IV_"
   },
   "source": [
    "### MinMaxScaler+SMOTE+XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Q3XVxuD9MZ9",
    "outputId": "bf980d0a-9882-408c-8400-0faa4991974c"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_normalized, y_train)\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "xgb_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test_normalized)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LfA2f50T9Mvm"
   },
   "source": [
    "### RobustScaler+SMOTE+XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3x9fRPZt9O6Y",
    "outputId": "e2050bed-0c23-4023-ed76-bc9e49f56149"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_robust, y_train)\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "xgb_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test_robust)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fzTdGnX4BJnv"
   },
   "source": [
    "### PCA+SMOTE+XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kaGiu2kCBNqm",
    "outputId": "e9dbf460-691b-4ebb-a30f-907e461da447"
   },
   "outputs": [],
   "source": [
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "\n",
    "for i, X_pca_output in enumerate(X_pca_list):\n",
    "    print(f\"\\n=== Processing PCA Result with {X_pca_output.shape[1]} Features ===\")\n",
    "\n",
    "\n",
    "    # scaler = StandardScaler()\n",
    "    # X_train_scaled = scaler.fit_transform(X_pca_output)\n",
    "    # X_test_pca = scaler.transform(XT_pca_list[i])\n",
    "\n",
    "\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_pca_output, y_train)\n",
    "\n",
    "\n",
    "    print(\"Resampled class distribution in training set:\")\n",
    "    print(y_train_resampled.value_counts())\n",
    "\n",
    "\n",
    "    model = XGBClassifier(random_state=42)\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "\n",
    "    y_pred = model.predict(XT_pca_list[i])\n",
    "\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hE6uvIiEBjuo"
   },
   "source": [
    "### PCA+StandardScaler+SMOTE+XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RhsWrS1iBx83",
    "outputId": "454eceb5-a1f2-4888-f7bd-32126521f628"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "class_counts = y_train.value_counts()\n",
    "scale_pos_weight = class_counts[0] / class_counts[1]\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "\n",
    "for i, X_pca_output in enumerate(X_pca_list):\n",
    "    print(f\"\\n=== Processing PCA Result with {X_pca_output.shape[1]} Features ===\")\n",
    "\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_pca_output)\n",
    "    X_test_pca = scaler.transform(XT_pca_list[i])\n",
    "\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "    print(\"Resampled class distribution in training set:\")\n",
    "    print(y_train_resampled.value_counts())\n",
    "\n",
    "    model = XGBClassifier(random_state=42)\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ic2JmgUiIXuq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXZK3FkrBqtA"
   },
   "source": [
    "### PCA+MinMaxScaler+SMOTE+XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-XUdwNHrBy2Z",
    "outputId": "5d3bc88b-67da-465e-ebfb-7c23c9db6b2e"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "for i, X_pca_output in enumerate(X_pca_list):\n",
    "    print(f\"\\n=== Processing PCA Result with {X_pca_output.shape[1]} Features ===\")\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_pca_output)\n",
    "    X_test_pca = scaler.transform(XT_pca_list[i])\n",
    "\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "    print(\"Resampled class distribution in training set:\")\n",
    "    print(y_train_resampled.value_counts())\n",
    "\n",
    "    model = XGBClassifier(random_state=42)\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xi8fA9sdBrRp"
   },
   "source": [
    "### PCA+RobustScaler+SMOTE+XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CgCIozZTBorc",
    "outputId": "77b63dae-5b12-4dfc-ccb0-b67211eab4e5"
   },
   "outputs": [],
   "source": [
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "for i, X_pca_output in enumerate(X_pca_list):\n",
    "    print(f\"\\n=== Processing PCA Result with {X_pca_output.shape[1]} Features ===\")\n",
    "\n",
    "    scaler = RobustScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_pca_output)\n",
    "    X_test_pca = scaler.transform(XT_pca_list[i])\n",
    "\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "    print(\"Resampled class distribution in training set:\")\n",
    "    print(y_train_resampled.value_counts())\n",
    "\n",
    "    model = XGBClassifier(random_state=42)\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dx7YykAUHvdd"
   },
   "source": [
    "### SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U52U59CWHul3",
    "outputId": "0fa77ed2-e09b-449b-df96-eb44de9781df"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "smote = SMOTEENN(random_state=42)\n",
    "\n",
    "for i, X_pca_output in enumerate(X_pca_list):\n",
    "    print(f\"\\n=== Processing PCA Result with {X_pca_output.shape[1]} Features ===\")\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_pca_output)\n",
    "    X_test_pca = scaler.transform(XT_pca_list[i])\n",
    "\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "    print(\"Resampled class distribution in training set:\")\n",
    "    print(y_train_resampled.value_counts())\n",
    "\n",
    "    model = XGBClassifier(random_state=42)\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDR_3WjWbaiO"
   },
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gLnHySd__a4n"
   },
   "source": [
    "### Only RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XTrZIJyg_d7w",
    "outputId": "2e386c1a-0c0f-4ecc-b064-5da2894cba59"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qIuvtHUl1h2d"
   },
   "source": [
    "### SMOTE + RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZFaU5Jbmy6Vh",
    "outputId": "bcf6af93-433a-4db7-ec9c-679f834b53f1"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Resampled class distribution in training set:\")\n",
    "print(y_train_resampled.value_counts())\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGN_xcDa-vry"
   },
   "source": [
    "### StanderScaler+SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fEE9LXy1-zw2",
    "outputId": "924cc84a-3dba-42a6-8c27-ed6d8005e2ca"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Resampled class distribution in training set:\")\n",
    "print(y_train_resampled.value_counts())\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lV9HONM01vBK"
   },
   "source": [
    "### MinMaxScaler+SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OnRF5Ah-0yJq",
    "outputId": "8f2fcb6d-734a-4f99-e382-0bee2b811436"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_normalized, y_train)\n",
    "\n",
    "print(\"Resampled class distribution in training set:\")\n",
    "print(y_train_resampled.value_counts())\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test_normalized)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zYca-DYp93uX"
   },
   "source": [
    "### RobustScaler+SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vAhI8YGe024P",
    "outputId": "c839bebc-0aea-44b5-d948-ae09fceb23d4"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_robust, y_train)\n",
    "\n",
    "print(\"Resampled class distribution in training set:\")\n",
    "print(y_train_resampled.value_counts())\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test_robust)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ln6pU0aC3V59"
   },
   "source": [
    "### PCA+SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YDYpTZaG3VtA",
    "outputId": "f3f89c50-afb8-4b5a-bc13-e94bdbd2f0cd"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "for i, X_pca_output in enumerate(X_pca_list):\n",
    "    print(f\"\\n=== Processing PCA Result with {X_pca_output.shape[1]} Features ===\")\n",
    "\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_pca_output, y_train)\n",
    "\n",
    "    print(\"Resampled class distribution in training set:\")\n",
    "    print(y_train_resampled.value_counts())\n",
    "\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    X_test_pca = XT_pca_list[i]\n",
    "\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4dTsf6U11m-s"
   },
   "source": [
    "### StandardScaler+SMOTE+RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P88GUrWy0pa6",
    "outputId": "ee19df09-1ba5-446e-e78c-135e545db644"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_scaled_df, y_train)\n",
    "\n",
    "print(\"Resampled class distribution in training set:\")\n",
    "print(y_train_resampled.value_counts())\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UgMhOyjvbk35"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5fJ1q3h5FWf"
   },
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08w9Xua55Gyx",
    "outputId": "d2679f02-64bc-4480-b96d-887d26af87d3"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WpplGP_7HpA"
   },
   "source": [
    "### NONE+SMOTE+Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DC5N9HEB7G39",
    "outputId": "c5a468b3-7397-4029-df04-2240139a4c8f"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nVftp6Er7Zu5"
   },
   "source": [
    "### StandardScaler+SMOTE+LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iL1WhXOg7j3h",
    "outputId": "e20f1be4-4125-43b7-d117-3e3f524a278e"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "model = LogisticRegression(random_state=42, solver='liblinear', class_weight='balanced')\n",
    "\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-sau1cD8QK4"
   },
   "source": [
    "### MinMaxScale+SMOTE+LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aEcwwWbN8bAv",
    "outputId": "519cf71d-20c0-4df4-bfa7-c03d348faedd"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_normalized, y_train)\n",
    "\n",
    "model = LogisticRegression(random_state=42, solver='liblinear', class_weight='balanced')\n",
    "\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test_normalized)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPMJqOaX8WO0"
   },
   "source": [
    "### RobustScaler+SMOTE+LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TdlLaKgV8bYM",
    "outputId": "87a29526-f256-4aaf-be52-22427c66a0a1"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_robust, y_train)\n",
    "\n",
    "model = LogisticRegression(random_state=42, solver='liblinear', class_weight='balanced')\n",
    "\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test_robust)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fwa6zd2x83xc"
   },
   "source": [
    "### PCA+SMOTE+LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4bLx1BXn86Dx",
    "outputId": "6fd5bc06-f781-45da-d534-cb5de245ed5d"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "for i, X_pca_output in enumerate(X_pca_list):\n",
    "    print(f\"\\n=== Processing PCA Result with {X_pca_output.shape[1]} Features ===\")\n",
    "\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_pca_output, y_train)\n",
    "\n",
    "    print(\"Resampled class distribution in training set:\")\n",
    "    print(y_train_resampled.value_counts())\n",
    "\n",
    "    model = LogisticRegression(random_state=42, solver='liblinear', class_weight='balanced')\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    X_test_pca = XT_pca_list[i]\n",
    "\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wc70kaUQ9pEw"
   },
   "source": [
    "### PCA+StandardScaler+SMOTE+LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S_BMRMeL9xAQ",
    "outputId": "fa2ac623-4dee-46d5-df55-7f283194c6f6"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "for i, X_pca_output in enumerate(X_pca_list):\n",
    "    print(f\"\\n=== Processing PCA Result with {X_pca_output.shape[1]} Features ===\")\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_pca_output_scaled = scaler.fit_transform(X_pca_output)\n",
    "    X_test_pca_scaled = scaler.transform(XT_pca_list[i])\n",
    "\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_pca_output_scaled, y_train)\n",
    "\n",
    "    print(\"Resampled class distribution in training set:\")\n",
    "    print(y_train_resampled.value_counts())\n",
    "\n",
    "    model = LogisticRegression(random_state=42, solver='liblinear', class_weight='balanced')\n",
    "\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    y_pred = model.predict(X_test_pca_scaled)\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mx91jooV92C8"
   },
   "source": [
    "### PCA+MinMaxScale+SMOTE+LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QtVYuzLP-D_p",
    "outputId": "274c55c6-49dc-444e-f42f-7fcfa1f8ab2b"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "for i, X_pca_output in enumerate(X_pca_list):\n",
    "    print(f\"\\n=== Processing PCA Result with {X_pca_output.shape[1]} Features ===\")\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_pca_output_scaled = scaler.fit_transform(X_pca_output)\n",
    "    X_test_pca_scaled = scaler.transform(XT_pca_list[i])\n",
    "\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_pca_output_scaled, y_train)\n",
    "\n",
    "    print(\"Resampled class distribution in training set:\")\n",
    "    print(y_train_resampled.value_counts())\n",
    "\n",
    "    model = LogisticRegression(random_state=42, solver='liblinear', class_weight='balanced')\n",
    "\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    y_pred = model.predict(X_test_pca_scaled)\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9Xbem0w99XH"
   },
   "source": [
    "### PCA+RobustScale+SMOTE+LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZTa9rsMJ-Emk",
    "outputId": "e2225806-5d13-4389-afe0-7cffeeff23fe"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "for i, X_pca_output in enumerate(X_pca_list):\n",
    "    print(f\"\\n=== Processing PCA Result with {X_pca_output.shape[1]} Features ===\")\n",
    "\n",
    "    scaler = RobustScaler()\n",
    "    X_pca_output_scaled = scaler.fit_transform(X_pca_output)\n",
    "    X_test_pca_scaled = scaler.transform(XT_pca_list[i])\n",
    "\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_pca_output_scaled, y_train)\n",
    "\n",
    "    print(\"Resampled class distribution in training set:\")\n",
    "    print(y_train_resampled.value_counts())\n",
    "\n",
    "    model = LogisticRegression(random_state=42, solver='liblinear', class_weight='balanced')\n",
    "\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    y_pred = model.predict(X_test_pca_scaled)\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uknt5sqIbo4r"
   },
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLUuQw2u0e-e"
   },
   "source": [
    "### MPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RLEcUX4l04sB",
    "outputId": "30d17878-99b4-4af4-93fe-33b4606771ae"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 32),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGZ-A2ix0st4"
   },
   "source": [
    "### StandardScaler+mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Ml4TdqM0wCE",
    "outputId": "e795df35-c46a-402f-a62a-2ae3b7804789"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_pca = scaler.transform(X_test)\n",
    "\n",
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 32),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_pca)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvc6m66d0wYy"
   },
   "source": [
    "### MinMaxScaler+mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bmVncwmV0zj6",
    "outputId": "3f494dc2-c619-4c5e-c297-5d43ff617e63"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_pca = scaler.transform(X_test)\n",
    "\n",
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 32),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_pca)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQRVVcu700MC"
   },
   "source": [
    "### RobustScaler+mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1myAXd2F029r",
    "outputId": "4c291f55-294d-4796-f690-3ef9cfcb11d6"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_pca = scaler.transform(X_test)\n",
    "\n",
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 32),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_pca)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2n6nzA822N5e"
   },
   "source": [
    "### PCA+mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s3dE_0YG2Q4d",
    "outputId": "fbab734f-f414-44ad-fd2a-078330b48261"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "for i, X_pca_output in enumerate(X_pca_list):\n",
    "    print(f\"\\n=== Processing PCA Result with {X_pca_output.shape[1]} Features ===\")\n",
    "\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_pca_output, y_train)\n",
    "\n",
    "    print(\"Resampled class distribution in training set:\")\n",
    "    print(y_train_resampled.value_counts())\n",
    "\n",
    "    model = MLPClassifier(\n",
    "        hidden_layer_sizes=(128, 32),\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        max_iter=300,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    y_pred = model.predict(XT_pca_list[i])\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_3M7DkNTwnm9"
   },
   "source": [
    "### SMOTE+mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e-WrXnwiwm8H",
    "outputId": "b231d6b5-7f33-46c1-810d-235873a4f8ae"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Resampled class distribution in training set:\")\n",
    "print(y_train_resampled.value_counts())\n",
    "\n",
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 32),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HBFimonE0eMA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tsvHAUyp6w6o"
   },
   "source": [
    "### StandardScaler+SMOTE+mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qrowu35D64-O",
    "outputId": "5eedbacc-b008-41ee-ade9-d64d12c46edf"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Resampled class distribution in training set:\")\n",
    "print(y_train_resampled.value_counts())\n",
    "\n",
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 32),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5E0312O61LQ"
   },
   "source": [
    "### MinMaxScaler+SMOTE+MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wpGNhR7D65jP",
    "outputId": "3ad4bc11-272e-46d5-faee-82ee60f228ff"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Resampled class distribution in training set:\")\n",
    "print(y_train_resampled.value_counts())\n",
    "\n",
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 32),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hns_jSub63NW"
   },
   "source": [
    "### RobustScaler+SMOTE+MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DIxzcjJ-66wb",
    "outputId": "41793ba0-1acf-4e10-eb44-42dd76f9e2ff"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Resampled class distribution in training set:\")\n",
    "print(y_train_resampled.value_counts())\n",
    "\n",
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 32),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-x0A0Hy_YJd"
   },
   "source": [
    "### PCA+SMOTE+mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DnFkqxsB_V0x",
    "outputId": "ffcadead-4ed9-4bb2-9d7b-b1bc29a5947c"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "for i, X_pca_output in enumerate(X_pca_list):\n",
    "    print(f\"\\n=== Processing PCA Result with {X_pca_output.shape[1]} Features ===\")\n",
    "\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_pca_output, y_train)\n",
    "\n",
    "    print(\"Resampled class distribution in training set:\")\n",
    "    print(y_train_resampled.value_counts())\n",
    "\n",
    "    model = MLPClassifier(\n",
    "        hidden_layer_sizes=(128, 32),\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        max_iter=300,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    y_pred = model.predict(XT_pca_list[i])\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "byEN-1Bk-gfy"
   },
   "source": [
    "### PCA+StandardScaler+SMOTE+mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9qE1AApY-lKz",
    "outputId": "c2f3cc09-5e68-46ea-8994-119e370daa14"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "for i, X_pca_output in enumerate(X_pca_list):\n",
    "    print(f\"\\n=== Processing PCA Result with {X_pca_output.shape[1]} Features ===\")\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_pca_output)\n",
    "    X_test_pca = scaler.transform(XT_pca_list[i])\n",
    "\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "    print(\"Resampled class distribution in training set:\")\n",
    "    print(y_train_resampled.value_counts())\n",
    "\n",
    "    model = MLPClassifier(\n",
    "        hidden_layer_sizes=(128, 32),\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        max_iter=300,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EgvE82pRsiq3"
   },
   "source": [
    "### PCA+MinMaxScaler+SMOTE+MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WbHvQp4Vsnaq",
    "outputId": "4c00f18d-5d6d-4536-ddd3-b9257e091c35"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "for i, X_pca_output in enumerate(X_pca_list):\n",
    "    print(f\"\\n=== Processing PCA Result with {X_pca_output.shape[1]} Features ===\")\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_pca_output)\n",
    "    X_test_pca = scaler.transform(XT_pca_list[i])\n",
    "\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "    print(\"Resampled class distribution in training set:\")\n",
    "    print(y_train_resampled.value_counts())\n",
    "\n",
    "    model = MLPClassifier(\n",
    "        hidden_layer_sizes=(128, 32),\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        max_iter=300,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bkwPHpOlsnzb"
   },
   "source": [
    "### PCA+RobustScaler+SMOTE+MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "esoA6Ym9swVg",
    "outputId": "27401956-0c67-4ce0-b6f8-b8a0cf6648c0"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "for i, X_pca_output in enumerate(X_pca_list):\n",
    "    print(f\"\\n=== Processing PCA Result with {X_pca_output.shape[1]} Features ===\")\n",
    "\n",
    "    scaler = RobustScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_pca_output)\n",
    "    X_test_pca = scaler.transform(XT_pca_list[i])\n",
    "\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "    print(\"Resampled class distribution in training set:\")\n",
    "    print(y_train_resampled.value_counts())\n",
    "\n",
    "    model = MLPClassifier(\n",
    "        hidden_layer_sizes=(128, 32),\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        max_iter=300,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6h5h85qxEAdP"
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EpdhT-kuEECA",
    "outputId": "8229dc0a-581a-4968-f41d-7cc18e8e8c11"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "svm_model = SVC(kernel='rbf', C=1, gamma='scale', random_state=42, class_weight='balanced')\n",
    "svm_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred_svm = svm_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "M72_86q8c3VM",
    "kFgtiYHr_zWa",
    "6r92EeCdbOf2",
    "TulESSJ99B3T"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
